<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Chapter 8 Future Study of Intelligence ‣ Learning Deep Representations of Data Distributions</title>
<!--Generated on Mon Aug 18 12:37:23 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on August 18, 2025.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/gh/arXiv/arxiv-browse@master/arxiv/browse/static/css/ar5iv.0.8.2.min.css" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/gh/arXiv/arxiv-browse@master/arxiv/browse/static/css/ar5iv-fonts.0.8.2.min.css" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/gh/arXiv/arxiv-browse@master/arxiv/browse/static/css/latexml_styles.0.8.2.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<link href="book.css" rel="stylesheet" type="text/css"/><script defer="defer" src="shared-ui.js"></script><script defer="defer" src="book.js"></script></head>
<body id="top">
<nav class="ltx_page_navbar"><a class="ltx_ref" href="book-main.html" rel="start" title=""><span class="ltx_text ltx_ref_title">Learning Deep Representations of Data Distributions</span></a>
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_chapter"><a class="ltx_ref" href="Chx1.html" title="In Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title">Preface</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a class="ltx_ref" href="Chx2.html" title="In Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title">Declaration of Open Source</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a class="ltx_ref" href="Chx3.html" title="In Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title">Acknowledgment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a class="ltx_ref" href="Ch1.html" title="In Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a class="ltx_ref" href="Ch2.html" title="In Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Learning Linear and Independent Structures</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a class="ltx_ref" href="Ch3.html" title="In Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Pursuing Low-Dimensional Distributions via Lossy Compression</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a class="ltx_ref" href="Ch4.html" title="In Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Deep Representations from Unrolled Optimization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a class="ltx_ref" href="Ch5.html" title="In Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Consistent and Self-Consistent Representations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a class="ltx_ref" href="Ch6.html" title="In Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Inference with Low-Dimensional Distributions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter"><a class="ltx_ref" href="Ch7.html" title="In Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Learning Representations for Real-World Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_chapter ltx_ref_self">
<span class="ltx_ref ltx_ref_self"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Future Study of Intelligence</span></span>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S1" title="In Chapter 8 Future Study of Intelligence ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1 </span>Towards Autonomous Intelligence: Close the Loop?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S2" title="In Chapter 8 Future Study of Intelligence ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2 </span>Towards Intelligence of Nature: Beyond Back Propagation?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S3" title="In Chapter 8 Future Study of Intelligence ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.3 </span>Towards Artificial Intelligence of Human: Beyond the Turing Test?</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="A1.html" title="In Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Optimization Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="A2.html" title="In Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Entropy, Diffusion, Denoising, and Lossy Coding</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<header class="ltx_page_header">
</header>
<div class="ltx_page_content">
<section class="ltx_chapter ltx_authors_1line">
<h1 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 8 </span>Future Study of Intelligence</h1><div class="mini-toc"><div class="mini-toc-title">In this chapter</div><ul><li><a href="#S1">Towards Autonomous Intelligence: Close the Loop?</a></li><li><a href="#S2">Towards Intelligence of Nature: Beyond Back Propagation?</a></li><li><a href="#S3">Towards Artificial Intelligence of Human: Beyond the Turing Test?</a></li></ul></div>
<div class="ltx_para" id="p1">
<blockquote class="ltx_quote">
<p class="ltx_p">“<span class="ltx_text ltx_font_italic">The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problem now reserved for humans, and improve themselves.</span>”</p>
<p class="ltx_p">  – Proposal for the Dartmouth AI program, 1956</p>
</blockquote>
</div>
<div class="ltx_para" id="p2">
<p class="ltx_p">Generally speaking, this manuscript is meant to systematically introduce mathematical principles and computational mechanisms for how memory or knowledge can be developed from empirical observations. The capability to seek parsimony in a seemingly random world is a fundamental characteristic of any intelligence, natural or man-made. We believe that the principles and mechanisms presented in this book are rather unifying and universal and are applicable to both animals and machines.</p>
</div>
<div class="ltx_para" id="p3">
<p class="ltx_p">We hope that this book can help the readers fully clarify the mystery around modern practices of artificial deep neural networks by developing a rigorous understanding of their functions and roles in achieving the objective of learning low-dimensional distributions from high-dimensional data. With such a understanding, we should have become rather clear both capabilities and limitations of existing AI models and systems:</p>
<ol class="ltx_enumerate" id="S0.I1">
<li class="ltx_item" id="S0.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S0.I1.i1.p1">
<p class="ltx_p">Existing models and systems are short of being complete in terms of a memory system that is capable of self-learning and self-improving.</p>
</div>
</li>
<li class="ltx_item" id="S0.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S0.I1.i2.p1">
<p class="ltx_p">Existing realizations of these functions are still rather primitive and brute force and certainly far from optimal in terms of optimization strategies hence network architectures.</p>
</div>
</li>
<li class="ltx_item" id="S0.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S0.I1.i3.p1">
<p class="ltx_p">Existing AI models only learn the data distribution and conduct inductive (Bayesian) inference, which is different from the high-level human intelligence.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="p4">
<p class="ltx_p">One of the goals of this book is for people to establish an objective and systematic understanding of current machine intelligence technologies and to realize what open problems and challenges remain ahead for further advancement of machine intelligence. In the last chapter of the book, we provide some of our views and projections for the future.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8.1 </span>Towards Autonomous Intelligence: Close the Loop?</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p">From the practice of machine intelligence in the past decade, it has become clear that, if there were sufficient data and computational resources, one could build a large enough model and pre-train it to learn the <span class="ltx_text ltx_font_italic">a priori</span> distribution of all the data, say <math alttext="p(\bm{x})" class="ltx_Math" display="inline" id="S1.p1.m1"><semantics><mrow><mi>p</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(\bm{x})</annotation><annotation encoding="application/x-llamapun">italic_p ( bold_italic_x )</annotation></semantics></math>. Theoretically, such a large model can memorize almost all existing knowledge about the world that has been encoded in massive languages and texts. As we have discussed at the beginning of the book, in a way, such a large model plays a similar role as DNAs with which life uses to record and pass on knowledge about the world.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p">The so learned model and distribution can then be used to regenerate new data samples based on the same distribution. One can also use the model to conduct inference (e.g., estimation, prediction) with the memorized knowledge under various conditions, say by sampling the <span class="ltx_text ltx_font_italic">a posteriori</span> distribution <math alttext="p(\bm{x}\mid\bm{y})" class="ltx_Math" display="inline" id="S1.p2.m1"><semantics><mrow><mi>p</mi><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>𝒙</mi><mo>∣</mo><mi>𝒚</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(\bm{x}\mid\bm{y})</annotation><annotation encoding="application/x-llamapun">italic_p ( bold_italic_x ∣ bold_italic_y )</annotation></semantics></math> under a new observation <math alttext="\bm{y}" class="ltx_Math" display="inline" id="S1.p2.m2"><semantics><mi>𝒚</mi><annotation encoding="application/x-tex">\bm{y}</annotation><annotation encoding="application/x-llamapun">bold_italic_y</annotation></semantics></math>. Strictly speaking, such inference is statistical.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p">Any pre-trained model, however large, cannot guarantee that the distribution that it has learned so far is entirely correct or complete. In case our samples <math alttext="\hat{\bm{x}}_{t}" class="ltx_Math" display="inline" id="S1.p3.m1"><semantics><msub><mover accent="true"><mi>𝒙</mi><mo>^</mo></mover><mi>t</mi></msub><annotation encoding="application/x-tex">\hat{\bm{x}}_{t}</annotation><annotation encoding="application/x-llamapun">over^ start_ARG bold_italic_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> from the current <span class="ltx_text ltx_font_italic">a priori</span> <math alttext="p_{t}(\bm{x})" class="ltx_Math" display="inline" id="S1.p3.m2"><semantics><mrow><msub><mi>p</mi><mi>t</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">p_{t}(\bm{x})</annotation><annotation encoding="application/x-llamapun">italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( bold_italic_x )</annotation></semantics></math> or estimates <math alttext="\hat{\bm{x}}_{t}(\bm{y})" class="ltx_Math" display="inline" id="S1.p3.m3"><semantics><mrow><msub><mover accent="true"><mi>𝒙</mi><mo>^</mo></mover><mi>t</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>𝒚</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{\bm{x}}_{t}(\bm{y})</annotation><annotation encoding="application/x-llamapun">over^ start_ARG bold_italic_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( bold_italic_y )</annotation></semantics></math> based on the <span class="ltx_text ltx_font_italic">a posteriori</span> <math alttext="p_{t}(\bm{x}\mid\bm{y})" class="ltx_Math" display="inline" id="S1.p3.m4"><semantics><mrow><msub><mi>p</mi><mi>t</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>𝒙</mi><mo>∣</mo><mi>𝒚</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">p_{t}(\bm{x}\mid\bm{y})</annotation><annotation encoding="application/x-llamapun">italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( bold_italic_x ∣ bold_italic_y )</annotation></semantics></math> are inconsistent with the truth <math alttext="\bm{x}" class="ltx_Math" display="inline" id="S1.p3.m5"><semantics><mi>𝒙</mi><annotation encoding="application/x-tex">\bm{x}</annotation><annotation encoding="application/x-llamapun">bold_italic_x</annotation></semantics></math>, we would very much like to correct the learned distributions:</p>
<table class="ltx_equation ltx_eqn_table" id="S1.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p_{t}(\bm{x})\rightarrow p_{t+1}(\bm{x})\quad\mbox{or}\quad p_{t}(\bm{x}\mid\bm{y})\rightarrow p_{t+1}(\bm{x}\mid\bm{y})," class="ltx_Math" display="block" id="S1.E1.m1"><semantics><mrow><mrow><mrow><mrow><msub><mi>p</mi><mi>t</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">→</mo><mrow><mrow><msub><mi>p</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow></mrow><mspace width="1em"></mspace><mtext>or</mtext></mrow></mrow><mspace width="1em"></mspace><mrow><mrow><msub><mi>p</mi><mi>t</mi></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>𝒙</mi><mo>∣</mo><mi>𝒚</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">→</mo><mrow><msub><mi>p</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo lspace="0em" rspace="0em">​</mo><mrow><mo stretchy="false">(</mo><mrow><mi>𝒙</mi><mo>∣</mo><mi>𝒚</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">p_{t}(\bm{x})\rightarrow p_{t+1}(\bm{x})\quad\mbox{or}\quad p_{t}(\bm{x}\mid\bm{y})\rightarrow p_{t+1}(\bm{x}\mid\bm{y}),</annotation><annotation encoding="application/x-llamapun">italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( bold_italic_x ) → italic_p start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ( bold_italic_x ) or italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( bold_italic_x ∣ bold_italic_y ) → italic_p start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT ( bold_italic_x ∣ bold_italic_y ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8.1.1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">based on the error <math alttext="\bm{e}_{t}=\bm{x}_{t}-\hat{\bm{x}}_{t}" class="ltx_Math" display="inline" id="S1.p3.m6"><semantics><mrow><msub><mi>𝒆</mi><mi>t</mi></msub><mo>=</mo><mrow><msub><mi>𝒙</mi><mi>t</mi></msub><mo>−</mo><msub><mover accent="true"><mi>𝒙</mi><mo>^</mo></mover><mi>t</mi></msub></mrow></mrow><annotation encoding="application/x-tex">\bm{e}_{t}=\bm{x}_{t}-\hat{\bm{x}}_{t}</annotation><annotation encoding="application/x-llamapun">bold_italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = bold_italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - over^ start_ARG bold_italic_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. This is known as error correction based on error feedback, an ubiquitous mechanism in nature for continuous learning. However, as we know, any open-ended model itself does not have the mechanisms to revise or improve the learned distribution when it is incorrect or incomplete. Improving current AI models still largely depends on human involvement: experimentation, evaluation, and selection. We may call this process as “artificial selection” of large models, as opposed to the natural selection for the evolution of lives.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p">As we have studied earlier in this book (Chapter <a class="ltx_ref" href="Ch5.html" title="Chapter 5 Consistent and Self-Consistent Representations ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_tag">5</span></a> in particular), closed-loop systems allows to align an internal representation with the (sensed) observations of the external world. It can continue to improve the internally learned distribution and its representation to achieve consistency or self-consistency. An immediate step forward for the future is to develop and build truly closed-loop memory systems, as shown in Figure <a class="ltx_ref" href="#F1" title="Figure 8.1 ‣ 8.1 Towards Autonomous Intelligence: Close the Loop? ‣ Chapter 8 Future Study of Intelligence ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_tag">8.1</span></a>, that are capable of learning and improving more general data distributions autonomously and continuously based on error feedback.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p">Therefore, transition from the current popular end-to-end trained open-loop models to continuously-learning closed-loop systems:</p>
<table class="ltx_equation ltx_eqn_table" id="S1.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mbox{{open-ended} models}\;\Longrightarrow\;\mbox{{closed-loop} systems}" class="ltx_Math" display="block" id="S1.E2.m1"><semantics><mrow><mrow><mtext class="ltx_mathvariant_bold">open-ended</mtext><mtext> models</mtext></mrow><mo rspace="0.558em" stretchy="false">⟹</mo><mrow><mtext class="ltx_mathvariant_bold">closed-loop</mtext><mtext> systems</mtext></mrow></mrow><annotation encoding="application/x-tex">\mbox{{open-ended} models}\;\Longrightarrow\;\mbox{{closed-loop} systems}</annotation><annotation encoding="application/x-llamapun">bold_open-ended models ⟹ bold_closed-loop systems</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8.1.2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">is the key for machines to truly emulate how the (animal) brain learns and applies knowledge in an open world. We believe that</p>
<blockquote class="ltx_quote">
<p class="ltx_p ltx_align_center"><span class="ltx_text ltx_font_italic">open-ended models are for a closed world, however large; 
<br class="ltx_break"/>closed-loop systems are for an open world, however small.</span></p>
</blockquote>
<p class="ltx_p">In fact, “general intelligence” could never be achieved by simply having memorized all existing knowledge of the world. Instead, general intelligence can only be achieved by having the mechanisms to improve its existing memory so as to be able to adapt to any new environments and tasks.</p>
</div>
<figure class="ltx_figure" id="F1"><img alt="Figure 8.1 : From an open-ended deep network to a closed-loop system." class="ltx_graphics ltx_img_landscape" height="154" id="F1.g1" src="chapters/chapter8/figs/open-to-closed.png" width="538"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 8.1</span>: </span><span class="ltx_text" style="font-size:90%;">From an open-ended deep network to a closed-loop system.</span></figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8.2 </span>Towards Intelligence of Nature: Beyond Back Propagation?</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p">The practice of machine intelligence in the past few years has led many to believe that one needs to build a single large model to learn the distribution of all data and memorize all knowledge. Even if this might be technologically possible, it is likely that such a solution is far from necessary and efficient. As we have known from the practice of training deep networks, the only known scalable method to train such networks at scale is through back propagation (BP) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="bib.html#bibx236" title="">RHW86a</a>]</cite>. Although BP has offered a way to correct errors via gradient signals propagated back through the whole model, it is nevertheless rather brute force and differs significantly from how nature learns: BP is an option that nature cannot afford in terms of its high cost or simply cannot implement due to physical limitations.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p">More generally, we cannot truly understand intelligence unless we also understand how it can be efficiently implemented. That is, one needs to address the computational complexity of realizing mechanisms associated with achieving the objectives of intelligence. Note that, historically, our understanding of (machine) intelligence has precisely evolved through several phases, from the incomputable Kolmogorov complexity to Shannon’s entropy, from Turing’s computability to later understanding of tractability,<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We say a problem is tractable if it allows an algorithm whose complexity is polynomial in the size of the problem.</span></span></span> and to the strong emphasis on algorithm scalability in modern practice of artificial intelligence. This evolution can be summarized as the following diagram:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mbox{{incomputable}}\;\Longrightarrow\;\mbox{{computable}}\;\Longrightarrow\;\mbox{{tractable}}\;\Longrightarrow\;\mbox{{scalable}}." class="ltx_Math" display="block" id="S2.E1.m1"><semantics><mrow><mrow><mtext class="ltx_mathvariant_bold">incomputable</mtext><mo lspace="0.558em" rspace="0.558em" stretchy="false">⟹</mo><mtext class="ltx_mathvariant_bold">computable</mtext><mo lspace="0.558em" rspace="0.558em" stretchy="false">⟹</mo><mtext class="ltx_mathvariant_bold">tractable</mtext><mo lspace="0.558em" rspace="0.558em" stretchy="false">⟹</mo><mtext class="ltx_mathvariant_bold">scalable</mtext></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\mbox{{incomputable}}\;\Longrightarrow\;\mbox{{computable}}\;\Longrightarrow\;\mbox{{tractable}}\;\Longrightarrow\;\mbox{{scalable}}.</annotation><annotation encoding="application/x-llamapun">incomputable ⟹ computable ⟹ tractable ⟹ scalable .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8.2.1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">To a large extent, the success and popularity of deep learning and back propagation is precisely because they have offered a scalable implementation with modern computing platforms (such as GPUs) for processing and compressing massive data. Nevertheless, such an implementation is still way too more expensive compared to how nature realizes intelligence.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p">There remains a huge room for improvement of the efficiency of machine intelligence so that it can emulate the level of efficiency of natural intelligence, which should be of magnitudes more efficient than the current brute-force implementations. To this end, we need to discover new learning architectures and optimization mechanisms that enable learning data distributions under natural physical conditions and resource constraints, similar to those for intelligent beings in nature, say, without accessing all data at once or updating all model parameters at once (by BP).</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p">The principled framework and approach laid out in this book can guide us to discover such new architectures and mechanisms. These new architectures and mechanisms should enable online continuous learning and can be updated through highly localized and sparse forward or backward optimization. So far, for learning a distribution, the only case for which we know such a solution exists is the simplest case of PCA, with the online PCA method introduced in Chapter <a class="ltx_ref" href="Ch5.html" title="Chapter 5 Consistent and Self-Consistent Representations ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure class="ltx_figure" id="F2"><img alt="Figure 8.2 : Conjectured architecture of the brain cortex: The cortex is a massively parallel and distributed auto-encoding system that consists of a hierarchy of closed-loop auto-encoders that extract information from multiple senses and maximize the information gain of the resulting representations at multiple levels of hierarchy and granularity." class="ltx_graphics ltx_img_landscape" height="163" id="F2.g1" src="chapters/chapter8/figs/loops.png" width="592"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 8.2</span>: </span><span class="ltx_text" style="font-size:90%;">Conjectured architecture of the brain cortex: The cortex is a massively parallel and distributed auto-encoding system that consists of a hierarchy of closed-loop auto-encoders that extract information from multiple senses and maximize the information gain of the resulting representations at multiple levels of hierarchy and granularity.</span></figcaption>
</figure>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p">As we have learned from neuroscience, the cortex of our brain consists of tens of thousands of cortical columns. All cortical columns have similar physical structures and functions. They are highly parallel and distributed, though sparsely interconnected. Hence, we believe that in order to develop a more scalable and structured memory system, we need to consider architectures that emulate that of the cortex. Figure <a class="ltx_ref" href="#F2" title="Figure 8.2 ‣ 8.2 Towards Intelligence of Nature: Beyond Back Propagation? ‣ Chapter 8 Future Study of Intelligence ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_tag">8.2</span></a> shows such a hypothesized architecture, a massively distributed and hierarchical system that consists of many largely parallel closed-loop auto-encoding modules. These modules learn to encode different sensory modalities or many projections of data from each sensory modality. Our discussion in Section <a class="ltx_ref" href="Ch6.html#S5" title="6.5 Conditional Inference with Measurement Self-Consistency ‣ Chapter 6 Inference with Low-Dimensional Distributions ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_tag">6.5</span></a> of Chapter <a class="ltx_ref" href="Ch6.html" title="Chapter 6 Inference with Low-Dimensional Distributions ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_tag">6</span></a> suggests that such a parallel sensing and learning of a low-dimensional distribution is theoretically possible. Higher-level (lossy) autoencoders can then be learned based on outputs of lower-level ones to develop more sparse and higher-level “abstractions” of the representations learned by the lower levels.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p">The distributed, hierarchical, and closed-loop system architecture illustrated in Figure <a class="ltx_ref" href="#F2" title="Figure 8.2 ‣ 8.2 Towards Intelligence of Nature: Beyond Back Propagation? ‣ Chapter 8 Future Study of Intelligence ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_tag">8.2</span></a> shares many characteristics of cortex of the brain. Such a system architecture may open up many more possibilities than the current single large-model architecture. It makes exploring much more efficient learning and optimization mechanisms possible, and resulting more structured modular organization of the learned data distribution and knowledge. This would allow us to bring the implementation of machine intelligence to the next level of evolution:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mbox{{incomputable}}\;\Longrightarrow\;\mbox{{computable}}\;\Longrightarrow\;\mbox{{tractable}}\;\Longrightarrow\;\mbox{{scalable}}\;\Longrightarrow\;\mbox{{natural}}." class="ltx_Math" display="block" id="S2.E2.m1"><semantics><mrow><mrow><mtext class="ltx_mathvariant_bold">incomputable</mtext><mo lspace="0.558em" rspace="0.558em" stretchy="false">⟹</mo><mtext class="ltx_mathvariant_bold">computable</mtext><mo lspace="0.558em" rspace="0.558em" stretchy="false">⟹</mo><mtext class="ltx_mathvariant_bold">tractable</mtext><mo lspace="0.558em" rspace="0.558em" stretchy="false">⟹</mo><mtext class="ltx_mathvariant_bold">scalable</mtext><mo lspace="0.558em" rspace="0.558em" stretchy="false">⟹</mo><mtext class="ltx_mathvariant_bold">natural</mtext></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\mbox{{incomputable}}\;\Longrightarrow\;\mbox{{computable}}\;\Longrightarrow\;\mbox{{tractable}}\;\Longrightarrow\;\mbox{{scalable}}\;\Longrightarrow\;\mbox{{natural}}.</annotation><annotation encoding="application/x-llamapun">incomputable ⟹ computable ⟹ tractable ⟹ scalable ⟹ natural .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8.2.2)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8.3 </span>Towards Artificial Intelligence of Human: Beyond the Turing Test?</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p">As we have discussed at the beginning of this book, Chapter <a class="ltx_ref" href="Ch1.html" title="Chapter 1 Introduction ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_tag">1</span></a>, intelligence in nature has evolved through multiple phases and manifested in four different forms:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mbox{{phylogentic}}\;\Longrightarrow\;\mbox{{ontogenetic}}\;\Longrightarrow\;\mbox{{societal}}\;\Longrightarrow\;\mbox{{artificial intelligence}}." class="ltx_Math" display="block" id="S3.E1.m1"><semantics><mrow><mrow><mtext class="ltx_mathvariant_bold">phylogentic</mtext><mo lspace="0.558em" rspace="0.558em" stretchy="false">⟹</mo><mtext class="ltx_mathvariant_bold">ontogenetic</mtext><mo lspace="0.558em" rspace="0.558em" stretchy="false">⟹</mo><mtext class="ltx_mathvariant_bold">societal</mtext><mo lspace="0.558em" rspace="0.558em" stretchy="false">⟹</mo><mtext class="ltx_mathvariant_bold">artificial intelligence</mtext></mrow><mo lspace="0em">.</mo></mrow><annotation encoding="application/x-tex">\mbox{{phylogentic}}\;\Longrightarrow\;\mbox{{ontogenetic}}\;\Longrightarrow\;\mbox{{societal}}\;\Longrightarrow\;\mbox{{artificial intelligence}}.</annotation><annotation encoding="application/x-llamapun">phylogentic ⟹ ontogenetic ⟹ societal ⟹ artificial intelligence .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8.3.1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">All forms of intelligence share the common objective of learning useful knowledge as certain low-dimensional distributions of sensed high-dimensional data about the world. However, they may differ significantly in the specific coding schemes adopted, the information encoded, computational mechanisms for learning and improving, and physical implementations of such mechanisms. Using the concepts and terminologies developed in this book, from the perspective of learning and representing information or knowledge from the distribution of the sensed data, the above four stages of intelligence developed in nature differ in the following three aspects:</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p">The codebook that one uses to learn and encode the intended information or knowledge.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p">The information or knowledge that are encoded and represented using the codebook.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p">The optimization mechanisms used to improve the information or knowledge encoded.</p>
</div>
</li>
</ol>
<p class="ltx_p">More specifically, the following table summarizes their main characteristics in the above three aspects:</p>
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Phylogentic</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Ontogenetic</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Societal</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Artificial</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;"><span class="ltx_text ltx_font_bold">Codebook</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Amino Acids</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Neurons</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Alphabet &amp; Words</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Mathematics/Logic</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;"><span class="ltx_text ltx_font_bold">Information</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Genes/DNAs</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Memory</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Languages/Texts</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Scientific Facts</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;"><span class="ltx_text ltx_font_bold">Optimization</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Reinforce Learning</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Error Feedback</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Trial &amp; Error</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" style="padding-bottom:2.15277pt;">Hypothesis Testing</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p">As we now know, humans have achieved two quantum leaps in intelligence in history.
The first is the development of spoken and written languages about five to ten thousand years ago. That has enabled human to share and pass on learned knowledge for generations, similar to the role of DNAs in nature. The second is the development of mathematics and logic about three thousand years ago, which have become a precise language for modern science. This new language has freed us from summarizing knowledge from observations in empirical forms and allowed us to formalize knowledge as verifiable or falsifiable theories either through mathematical deduction or experimental verification. Through hypothesis formulating, logic deduction, and experimental testing, we are able to proactively discover new knowledge that was previously impossible by passively learning from data distribution.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>such as causal relationships</span></span></span></p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p">As we have discussed in the Introduction (Chapter <a class="ltx_ref" href="Ch1.html" title="Chapter 1 Introduction ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_tag">1</span></a>), the 1956 “artificial intelligence” (AI) program precisely aimed to study high-level functions such as mathematical abstractions, logical inference, and problem solving that are believed to differentiate humans from animals:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mbox{{low-level} (animal) intelligence}\;\Longrightarrow\;\mbox{{high-level} (human) intelligence.}" class="ltx_Math" display="block" id="S3.E2.m1"><semantics><mrow><mrow><mtext class="ltx_mathvariant_bold">low-level</mtext><mtext> (animal) intelligence</mtext></mrow><mo rspace="0.558em" stretchy="false">⟹</mo><mrow><mtext class="ltx_mathvariant_bold">high-level</mtext><mtext> (human) intelligence.</mtext></mrow></mrow><annotation encoding="application/x-tex">\mbox{{low-level} (animal) intelligence}\;\Longrightarrow\;\mbox{{high-level} (human) intelligence.}</annotation><annotation encoding="application/x-llamapun">bold_low-level (animal) intelligence ⟹ bold_high-level (human) intelligence.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8.3.2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p">As we have clarified repeatedly in this book, much of the technological advances in machine intelligence in the past decades, although carried out under the name “AI”, is actually more closely related to the low-level intelligence shared by both animals and humans, which is mainly inductive. So far, there has been no evidence suggesting that these mechanisms alone would suffice to achieve high-level human intelligence that the original AI program truly aims to understand and emulate.</p>
</div>
<div class="ltx_para" id="S3.p4">
<p class="ltx_p">In fact, we know little about how to rigorously verify whether a system is truly capable of certain high-level intelligence, despite the fact that the Turing test has been proposed since 1950 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="bib.html#bibx267" title="">Tur50</a>]</cite>.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>In Turning’s proposal, the evaluator is a human. However, most human evaluators’ scientific training and knowledge can be limited and their conclusions can be subjective.</span></span></span> For long such a test was not deemed necessary since the capabilities of machines were far below that of a human (or even animal). However, given recent technological advances, many models and systems have claimed to reach and even surpass human intelligence. Therefore, it is high time to give a scientific and executable definition of the Turing test. That is, how do we systematically and objectively evaluate the level of intelligence for a given model or system? For example, how can we rigorously verify whether an intelligent system has truly grasped a certain abstract concept, such as the notion of natural or real numbers, or it has merely memorized a large number of instances? Note that the state-of-the-art large language models still struggle with simple mathematical questions like: “Whether 3.11 is larger or smaller than 3.9?”<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Note that some models have corrected their answers to questions of this kind via post engineering. Or some models have incorporated additional reasoning mechanisms based on verifying the immediate answers produced and correct them during reasoning. However, we leave it to the reader as an exercise to rigorously test whether any of the state-of-the-art language models truly understand the notion of numbers (natural, rational, real, and complex) and the associated arithmetic.</span></span></span>
How to verify whether a system truly understands the rules of logic and knows how to apply them rigorously or has simply memorized a large number of instances of practicing logic? Furthermore, is such a system even capable of correcting its own knowledge or developing new knowledge such as physical laws, mathematical concepts, or causal relationships? In summary, it is high time that we develop rigorous evaluation methods that can tell a system/model’s seemingly intelligent capability belongs to which of the following:</p>
<ol class="ltx_enumerate" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p">simply having memorized the distribution of some knowledge-carrying data and regenerating them;</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p">being able to autonomously and continuously develop new knowledge from new observations;</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p">truly having understood certain abstract knowledge and knowing how to apply it correctly;</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S3.I2.i4.p1">
<p class="ltx_p">being able to generate new scientific hypotheses or mathematical conjectures and verify them.</p>
</div>
</li>
</ol>
</div>
<figure class="ltx_figure" id="F3"><img alt="Figure 8.3 : Three tests for different levels or types of intelligence capabilities: the Wiener test, the Turing test, and the Popper test." class="ltx_graphics ltx_img_landscape" height="163" id="F3.g1" src="chapters/chapter8/figs/tests.png" width="568"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" style="font-size:90%;">Figure 8.3</span>: </span><span class="ltx_text" style="font-size:90%;">Three tests for different levels or types of intelligence capabilities: the Wiener test, the Turing test, and the Popper test.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.p5">
<p class="ltx_p">Figure <a class="ltx_ref" href="#F3" title="Figure 8.3 ‣ 8.3 Towards Artificial Intelligence of Human: Beyond the Turing Test? ‣ Chapter 8 Future Study of Intelligence ‣ Learning Deep Representations of Data Distributions"><span class="ltx_text ltx_ref_tag">8.3</span></a> illustrate that probably there should be at least three different types of tests to evaluate and differentiate different types of intelligence capabilities:</p>
<ol class="ltx_enumerate" id="S3.I3">
<li class="ltx_item" id="S3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I3.i1.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">The Norbert Wiener Test:</span> The evaluate whether a system is capable of improving and developing new knowledge of its own or simply receives information through reinforced or supervised learning;</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I3.i2.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">The Alan Turning Test:</span> The evaluate whether a system can understand abstract knowledge or simply learns its statistics and uses it for Bayesian inference.</p>
</div>
</li>
<li class="ltx_item" id="S3.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I3.i3.p1">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">The Karl Popper Test:</span> To evaluate whether a system is capable of exploring new knowledge through forming and verifying new theories based on self-consistency.</p>
</div>
</li>
</ol>
<p class="ltx_p">We believe that, for such evaluation methods, the evaluator should not be a human but a scientifically sound protocol and process, instead.</p>
</div>
<div class="ltx_para" id="S3.p6">
<p class="ltx_p">As we have seen throughout this entire book, <span class="ltx_text ltx_font_italic">compression</span> has played a most fundamental role in learning. It is the governing principle and a unified mechanism for identifying an (empirical) data distribution and organizing information encoded therein. To a large extent, it explains most of the practice of “artificial intelligence” in the past decade or so. Here the word “artificial” largely means “man-made.” An outstanding question for future study is whether <span class="ltx_text ltx_font_italic">compression alone</span> is sufficient to achieve all higher-level capabilities of intelligence listed above?</p>
<blockquote class="ltx_quote">
<p class="ltx_p ltx_align_center"><span class="ltx_text ltx_font_italic">Is compression all there is?</span></p>
</blockquote>
<p class="ltx_p">Whether abstraction, causal inference, logical reasoning, and hypothesis generating and the subsequent deduction are certain extended or extreme forms of compression? Is there some fundamental difference between identifying empirical) data distributions through compression from forming high-level abstract concepts and theories? Philosopher Sir Karl Popper has once suggested:</p>
<blockquote class="ltx_quote">
<p class="ltx_p ltx_align_center"><span class="ltx_text ltx_font_italic">“Science may be described as the art of systematic oversimplification.”</span></p>
</blockquote>
<p class="ltx_p">To a large extent, Science, and its associated codebook Mathematics, can be viewed as the most advanced form of intelligence, hence the true “artificial” part of our intelligence. Here the word “artificial” means what is unique to educated and enlightened humans, almost like a form of high art. We believe that uncovering and understanding the underlying mathematical principles and computational mechanisms of such higher-level intelligence will be the final frontier for Science, Mathematics, and Computation altogether!</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Aug 18 12:37:23 2025 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
